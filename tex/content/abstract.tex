% !TEX root = Clean-Thesis.tex
%
\pdfbookmark[0]{Abstract}{Abstract}
\chapter*{Abstract}
\label{sec:abstract}
%\vspace*{-10mm}
\add{Medical information is employed in different scenarios, such as education, training, diagnosis, and surgery.
Perception and interaction with different media and objects are the fundamental human activities, and they are, meanwhile, user specific.
Research are done to create personalized perception and interaction with the different medical information for students, patients, doctors.}

At first, a Magic Mirror framework is presented to create a mixed reality environment with an \textit{in-situ} augmented reality view. It tracks one user and finishes the registration between the medical information and the user based on the collected personal information.
It inherently allows the user to perform interactive registration to generate personalized perception. This opens interesting possibilities for personalized augmented reality for medical education and rehabilitation. Two user studies were designed to respectively assess the precision and acceptability of the Magic Mirror system for anatomy education. 
We also take advantage of the interactive mixed reality to generate personalized augmented reality applications for organ learning, muscle learning and rehabilitation exercise. In addition, functions, e.g. ``Organ explosion'' and ``Self-control virtual view'', are designed and implemented, and serious games are also developed in this framework.

A novel user interface is designed where we propose the Pointing At Several Targets (PAST) method that offers an approach to calculate a virtual eye center as the origin for the \textit{eye-rooted} pointing ray without tracking the eye gaze in an egocentric setting. Consequently, the user-specific pointing geometry is recovered for personalized interaction with ambient information without visual feedback.
%During the calibration process, the user is asked to perform pointing gestures towards several elements displayed successively within his/her field of view. A virtual eye center is then estimated as the pointing ray origin based on the fingertip position detected by a wearable sensing device. After this initial calibration, the wearable device recovers the pointing geometry to identify the target the user is pointing at taking the contextual information into account. 
The proposed method is mathematically analyzed and determined that the calibration is feasible with a measured accuracy of the recovered pointing ray below $0.9\degree$.
%The method is also evaluated in a user study consisting of 10 participants performing pointing interaction with objects shown on the display while wearing a RGB-D sensor. 
A user study shows that the calibration is independent of the environment and the pointing ray is recovered with an accuracy of $0.67 \pm 0.71\degree$ without any visual feedback. 
Based on the recovered pointing gesture, a novel user interface is introduced, allowing the surgeon to personally perform touchless interaction with the {various} medical systems, and switch effortlessly among them, all of this without modifying the systems' software and hardware.

%natrual perception and one-multi user supervision and teaching, training 
Finally, in conjunction with the proposed Magic Mirror framework and recovered pointing gesture, a framework for collaborative MR is introduced. The human-human communication is enhanced via pointing gesture and MR framework. 

\add{\textbf{Keywords:} Medical Information, Personalized Perception, Personalized Interaction, Augmented Reality, Pointing Gesture, Mixed Reality Environment}

%The framework is simply examined in two scenarios, anatomy teaching with a student and rehabilitation exercise with a nurse.

%\vspace*{20mm}
%
%{\usekomafont{chapter}Zusammenfassung}\label{sec:abstract-diff} \\
%
%\blindtext
